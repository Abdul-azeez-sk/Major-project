{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e3df14-aa4c-4e05-ba06-cda86ccba5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3721c2cf-1941-4c2e-ae48-581237872499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_dataset_DDate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c1d5f4-01c8-4fb7-829a-8d9659aba79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 711341 entries, 0 to 711340\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   DDate           711341 non-null  object \n",
      " 1   AmcName         711341 non-null  object \n",
      " 2   YardName        711341 non-null  object \n",
      " 3   CommName        711341 non-null  object \n",
      " 4   VarityName      711341 non-null  object \n",
      " 5   Arrivals        711341 non-null  float64\n",
      " 6   Minimum         711341 non-null  float64\n",
      " 7   Maximum         711341 non-null  float64\n",
      " 8   Model           711341 non-null  float64\n",
      " 9   Year            711341 non-null  int64  \n",
      " 10  Month           711341 non-null  int64  \n",
      " 11  DayOfWeek       711341 non-null  int64  \n",
      " 12  WeekOfYear      711341 non-null  int64  \n",
      " 13  IsRabiSeason    711341 non-null  int64  \n",
      " 14  IsKharifSeason  711341 non-null  int64  \n",
      " 15  PriceSpread     711341 non-null  float64\n",
      " 16  Volatility      711341 non-null  float64\n",
      " 17  LogArrivals     711341 non-null  float64\n",
      " 18  Quarter         711341 non-null  int64  \n",
      " 19  IsSummer        711341 non-null  int64  \n",
      " 20  IsWinter        711341 non-null  int64  \n",
      "dtypes: float64(7), int64(9), object(5)\n",
      "memory usage: 114.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c05105-c5fb-4ff2-9f31-39fec1a5b402",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "keys must be str, int, float, bool or None, not int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/encoding_map.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Step 3: Resample/aggregate by date (if needed)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m df_sorted \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:377\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys must be str, int, float, bool or None, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    378\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first:\n\u001b[0;32m    380\u001b[0m     first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: keys must be str, int, float, bool or None, not int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Load your DataFrame `df` here\n",
    "# df = pd.read_csv(\"your_file.csv\")  # or however you load it\n",
    "\n",
    "# Step 1: Convert DDate to datetime\n",
    "df['DDate'] = pd.to_datetime(df['DDate'])\n",
    "\n",
    "# Step 2: Encode categorical variables and save encoders\n",
    "categorical_cols = ['AmcName', 'YardName', 'CommName', 'VarityName']\n",
    "encoding_map = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoding_map[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# Save encoding_map to a JSON file\n",
    "import os\n",
    "os.makedirs('output', exist_ok=True)\n",
    "with open('output/encoding_map.json', 'w') as f:\n",
    "    json.dump(encoding_map, f)\n",
    "\n",
    "# Step 3: Resample/aggregate by date (if needed)\n",
    "df_sorted = df.sort_values('DDate')\n",
    "df_grouped = df_sorted.groupby('DDate')['Model'].mean().asfreq('D')  # Daily average\n",
    "\n",
    "# Handle missing values (optional)\n",
    "df_grouped = df_grouped.fillna(method='ffill')\n",
    "\n",
    "# Step 4: Train/Test Split\n",
    "train_size = int(len(df_grouped) * 0.8)\n",
    "train, test = df_grouped.iloc[:train_size], df_grouped.iloc[train_size:]\n",
    "\n",
    "# Step 5: Fit ARIMA model\n",
    "model = ARIMA(train, order=(5, 1, 0))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Step 6: Forecast\n",
    "forecast = model_fit.forecast(steps=len(test))\n",
    "forecast.index = test.index\n",
    "\n",
    "# Step 7: Evaluation\n",
    "mae = mean_absolute_error(test, forecast)\n",
    "rmse = mean_squared_error(test, forecast, squared=False)\n",
    "r2 = r2_score(test, forecast)\n",
    "\n",
    "print(f\"\\n✅ ARIMA Model Performance:\")\n",
    "print(f\"MAE : {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²  : {r2:.2f}\")\n",
    "\n",
    "# Step 8: Save ARIMA model\n",
    "with open('/arima_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fit, f)\n",
    "\n",
    "print(\"\\n📁 Files saved:\")\n",
    "print(\"- /mnt/data/arima_model.pkl\")\n",
    "print(\"- /mnt/data/encoding_map.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc270c-4682-4589-8fa6-ec53adeb4b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
